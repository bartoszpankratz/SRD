{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wpowadzenie do deep learning w bibliotece Flux.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Flux](http://fluxml.ai/) jest biblioteką Julii przeznaczoną do tworzenia modeli uczenia maszynowego.\n",
    "- Jest w całości oparta na Julii, przez co trywialne jest jej modyfikowanie i dostosowywanie do swoich potrzeb. \n",
    "- Możliwe jest przy tym wykorzystanie wewnątrz modeli składni, funkcji i makr Julii.\n",
    "- Przy czym tworzenie całkiem złożonych standardowych modeli jest intuicyjne i szybkie, zazwyczaj zajmują one jedynie kilka linijek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dzisiejszych zajęciach skupimy się na przykładzie sieci MLP służącej do rozpoznawania odręcznie pisanych cyfr w zbiorze MNIST. Kod źródłowy dostępny jest [tutaj](https://github.com/FluxML/model-zoo/tree/master/vision/mnist).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Flux.Data.MNIST, Statistics, LinearAlgebra, Images\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle, Tracker\n",
    "using Base.Iterators: repeated\n",
    "# using CuArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszym krokiem jest oczywiście odpowiednie przygotowanie danych na których będziemy pracowali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify MNIST digits with a simple multi-layer-perceptron\n",
    "\n",
    "imgs = MNIST.images();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gray.(imgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack images into one large batch\n",
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = MNIST.labels()\n",
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(labels, 0:9) |> gpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i zbiór testowy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...) |> gpu;\n",
    "tY = onehotbatch(MNIST.labels(:test), 0:9) |> gpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Definiowanie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy dane są już gotowe kolejnym krokiem jest odpowiednie zdefiniowanie modelu na którym będziemy pracować. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zacznijmy od ręcznego zdefiniowania prostej warstwy sieci z sigmoidalną funkcją aktywacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = rand(4, 8)\n",
    "b = rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer₁(x) = 1.0 ./ (1.0.+exp.(-W*x - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rand(8)\n",
    "layer₁(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdybyśmy chcieli wyuczyć ten model we Fluxie to powyższa definicja regresji logistycznej nam wystarczy - musimy jedynie zadeklerować <tt>W</tt> i <tt>b</tt> jako trenowalne parametry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux.Tracker\n",
    "\n",
    "W = param(W)\n",
    "b = param(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oczywiście pracując na Fluxie nie musimy deklarować wszystkiego ręcznie, dostarcza on najpopularniejsze [funkcje aktywacji](http://fluxml.ai/Flux.jl/stable/models/layers.html#Activation-Functions-1), które możemy wykorzystać w naszym modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer₂(x) = σ.(W * x .+ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer₂(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogicznie nie ma konieczności definiowania [warstw modelu](http://fluxml.ai/Flux.jl/stable/models/layers.html#Basic-Layers-1) ręcznie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer₃ = Dense(8,4,σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer₃(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy czym gdy żadna z dostarczonych razem z Fluxem definicji warstwy nam nie odpowiada możemy w banalny sposób zadeklarować własną:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Affine\n",
    "  W\n",
    "  b\n",
    "end\n",
    "\n",
    "Affine(in::Integer, out::Integer) =\n",
    "  Affine(param(randn(out, in)), param(randn(out)))\n",
    "\n",
    "# Overload call, so the object can be used as a function\n",
    "(m::Affine)(x) = m.W * x .+ m.b\n",
    "\n",
    "a = Affine(10, 5)\n",
    "\n",
    "a(rand(10)) # => 5-element vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy chcemy móc w pełni wykorzystać wszystkie przydatne funkcje Fluxa musimy jeszcze skorzystać z makra <tt>treelike</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.@treelike Affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chcąc zbudować model z więcej niż jedną warstwą musimy go odpowiednio zdefiniować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer₁ = Dense(28^2, 32, relu)\n",
    "Layer₂ = Dense(32, 10)\n",
    "Layer₃ = softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m₁ = Chain(Layer₁ , Layer₂, Layer₃) |> gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja <tt>Chain</tt> pozwala łączyć w łancuchy dowolne funkcje w Julii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = Chain(x -> x^2, x-> -x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albo też:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m₂(x) = Layer₃(Layer₂(Layer₁(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lub jako złożenie funkcji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m₃(x) = Layer₁ ∘ Layer₂ ∘ Layer₃  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "czy też:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m₄(x) = Layer₁(x) |> Layer₂  |> Layer₃ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając już gotową definicję modelu możemy przejść do kolejnego punktu - wyboru funkcji celu i regularyzacji modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcja straty, regularyzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak poprzednio funkcję straty możemy zdefiniować samodzielnie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Dense(5,2)\n",
    "\n",
    "x, y = rand(5), rand(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(ŷ, y) = sum((ŷ.- y).^2)/ length(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(model(x), y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystać [jedną z zaimplementowanych we Fluxie:](https://github.com/FluxML/Flux.jl/blob/8f73dc6e148eedd11463571a0a8215fd87e7e05b/src/layers/stateless.jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.mse(model(x),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobnie [regularyzacja](http://fluxml.ai/Flux.jl/stable/models/regularisation.html) jest dość [intuicyjna](http://fluxml.ai/Flux.jl/stable/models/layers.html#Normalisation-and-Regularisation-1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty() =  norm(model.W) + norm(model.b)\n",
    "loss(ŷ,y) = Flux.mse(ŷ,y) + penalty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(model(x),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lub nawet prościej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(ŷ,y) = Flux.mse(ŷ,y) + sum(norm,params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(model(x),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inne metody regularyzacji mogą być [zaimplementowane jako warstwy:](http://fluxml.ai/Flux.jl/stable/models/layers.html#Normalisation-and-Regularisation-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(Dense(28^2, 32, relu),\n",
    "    Dropout(0.1),\n",
    "Dense(32, 10),\n",
    "BatchNorm(64, relu),\n",
    "softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W budowanym modelu funkcja straty wyglądać będzie następująco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = crossentropy(m₁(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uczenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po zdefiniowaniu modelu i funkcji celu możemy przystąpić do trenowania sieci."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podstawowym elementem pozwalającym uczyć modele jest odpowiedni algorytm liczący gradienty. We Fluxie implementacja wygląda następująco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = 3x^2 + 2x + 1\n",
    "\n",
    "# df/dx = 6x + 2\n",
    "df(x) = Tracker.gradient(f, x)[1]\n",
    "\n",
    "df(2) # 14.0 (tracked)\n",
    "\n",
    "# d²f/dx² = 6\n",
    "d2f(x) = Tracker.gradient(df, x)[1]\n",
    "\n",
    "d2f(2) # 6.0 (tracked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy funkcja ma wiele zmiennych wagi możemy przechowywać jako kolekcję i w ten sposób przekazywać do funkcji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = param(2) # 2.0 (tracked)\n",
    "b = param(3) # 3.0 (tracked)\n",
    "\n",
    "f(x) = W * x + b\n",
    "\n",
    "par = Flux.Params([W, b])\n",
    "grads = Tracker.gradient(() -> f(4), par)\n",
    "\n",
    "grads[W] # 4.0\n",
    "grads[b] # 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy prosty gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function simple_grad!(ps, η = .0001)\n",
    "  for w in ps\n",
    "    w.data .-= w.grad .* η\n",
    "    w.grad .= 0\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możliwe jest też zdefiniowanie [własnego algorytmu liczącego gradient](http://fluxml.ai/Flux.jl/stable/internals/tracker.html#Custom-Gradients-1) i przekazanie go do modelu - wszystkie metody, które mogliśmy dotychczas wykorzystać nadal będą działaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Własnoręczne definiowanie procesu optymalizacji nie jest konieczne, można wykorzystać [gotowy algorytm](http://fluxml.ai/Flux.jl/stable/training/optimisers.html) zaimplementowany we Fluxie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(params(m₁))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy prostą pętlę kontrolującą uczenie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "while true\n",
    "  back!(loss(model(x),y))\n",
    "  max(maximum(abs.(W.grad)), abs(b.grad[1])) > 0.001 || break\n",
    "  update!((W, b))\n",
    "  i += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux jest zdolny do kontrolowania całej procedury uczenia, nie musimy robić tego samodzielnie. Służy do tego funkcja <tt>train!</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(objective, data, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto jednak zaznaczyć, że pozwala ona na uczenie jedynie przez pojedynczą epokę. Aby móc kontynuować proces uczenia dalej musimy w odpowiedni sposób przystować dane z których korzystamy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = repeated((X, Y), 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albo skorzystać z makra <tt>@epochs</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.@epochs 2 println(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozwala ona też na definiowanie wywołań, które pozwolą nam kontrolować przebieg uczenia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalcb = () -> @show(loss(tX, tY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po omówieniu wszystkich elementów składowych biblioteki możemy złożyć naszą sieć w całość:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = MNIST.images()\n",
    "# Stack images into one large batch\n",
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu\n",
    "\n",
    "labels = MNIST.labels()\n",
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(labels, 0:9) |> gpu\n",
    "\n",
    "# Test set \n",
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...) |> gpu\n",
    "tY = onehotbatch(MNIST.labels(:test), 0:9) |> gpu\n",
    "\n",
    "\n",
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) |> gpu\n",
    "\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "dataset = repeated((X, Y), 200)\n",
    "evalcb = () -> @show(accuracy(tX, tY))\n",
    "opt = ADAM(params(m))\n",
    "\n",
    "Flux.train!(loss, dataset, opt, cb = throttle(evalcb, 10))\n",
    "\n",
    "println(\"training set accuracy: $(accuracy(X, Y))\")\n",
    "\n",
    "println(\"test set accuracy: $(accuracy(tX, tY))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oczywiście taka sieć może liczyć się strasznie długo. Ten proces można przyśpieszyć za pomocą wbudowanym w Julię wsparciu [obliczeń na GPU](http://fluxml.ai/Flux.jl/stable/gpu.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatywy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux nie jest jedyną biblioteką, która umożliwia budowanie modeli uczenia maszynowego w Julii. Poniżej wymienionych jest kilka alternatywnych możliwości:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Knet.jl](https://github.com/denizyuret/Knet.jl)\n",
    "- [MXnet.jl](https://github.com/dmlc/MXNet.jl)\n",
    "- [TensorFlow.jl](https://github.com/malmaud/TensorFlow.jl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
